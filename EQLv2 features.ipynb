{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_features_from_matterport import (\n",
    "    MatterportFeature, MatterportDataset, Arguments, load_viewpoints, \n",
    "    init_detector,inference_detector,filter_panorama, cartesian_to_polar\n",
    ")\n",
    "from typing import Tuple, Union, Sequence, List\n",
    "import pickle\n",
    "import lmdb\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.colors as mcolors\n",
    "from mmdet.datasets.lvis import LVISV1Dataset\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "classes = LVISV1Dataset.CLASSES\n",
    "\n",
    "sys.argv= ['foo']\n",
    "args = Arguments\n",
    "args.matterport = Path('matterport-views.lmdb')\n",
    "args.max_total_boxes = 100\n",
    "\n",
    "viewpoints = load_viewpoints(args)\n",
    "dataset = MatterportDataset(viewpoints, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features using EQLv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_id = 0\n",
    "model = init_detector(str(args.config), str(args.checkpoint), device=f'cuda:{device_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats, scan, viewpoint = dataset[2]\n",
    "scan = '17DRP5sb8fy'\n",
    "viewpoint = '08c774f20c984008882da2b8547850eb'\n",
    "key = f'{scan}_{viewpoint}'\n",
    "feats = dataset.txn.get(key.encode('ascii'))\n",
    "feats = pickle.loads(feats)\n",
    "\n",
    "\n",
    "all_boxes = []\n",
    "all_features = []\n",
    "all_probs = []\n",
    "all_view_ids = []\n",
    "all_labels = []\n",
    "\n",
    "for view_id, im in zip(feats['view_ids'], feats['image_feat']):\n",
    "\n",
    "    results = inference_detector(model, np.array(im))\n",
    "    assert len(results['bbox']) == len(results['features'])\n",
    "\n",
    "    all_boxes.append(results['bbox'])\n",
    "    all_probs.append(results['cls_score'])\n",
    "    all_features.append(results['features'])\n",
    "    all_labels.append(results['labels'])\n",
    "    num_bbox = results['bbox'].shape[0]\n",
    "    all_view_ids += [view_id] * num_bbox\n",
    "\n",
    "image_feat = torch.cat(all_features)\n",
    "bbox = torch.cat(all_boxes)\n",
    "probs = torch.cat(all_probs)\n",
    "view_ids = torch.Tensor(all_view_ids)\n",
    "labels = torch.cat(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_ind = filter_panorama(\n",
    "    bbox,\n",
    "    probs,\n",
    "    image_feat,\n",
    "    view_ids,\n",
    "#     args.max_total_boxes, \n",
    "    100,\n",
    "    feats['image_w'],\n",
    "    feats['image_h'],\n",
    "    feats['fov'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for view_id in range(36):\n",
    "    mask = view_ids[keep_ind] == view_id\n",
    "    if not mask.any():\n",
    "        continue\n",
    "    plt.imshow(np.array(feats['image_feat'][view_id])[:, :, ::-1])\n",
    "    ax = plt.gca()\n",
    "\n",
    "    for obj, vid, label, color in zip(bbox[keep_ind][mask], view_ids[keep_ind][mask], probs[keep_ind][mask], mcolors.TABLEAU_COLORS):\n",
    "        if vid != view_id:\n",
    "            continue\n",
    "        h = obj[3] - obj[1]\n",
    "        w = obj[2] - obj[0]\n",
    "        pos = (obj[0], obj[1])\n",
    "        rect = patches.Rectangle(\n",
    "            (pos), w, h, linewidth=1, \n",
    "            label=classes[label.argmax()],\n",
    "            edgecolor=color, \n",
    "            facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    plt.axis('off')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize pre-extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesReader:\n",
    "    def __init__(\n",
    "        self,\n",
    "        path: Union[Path, str]):\n",
    "        self._path = Path(path)\n",
    "\n",
    "        # open database\n",
    "        self._env = lmdb.open(\n",
    "            str(path),\n",
    "            readonly=True,\n",
    "            readahead=False,\n",
    "            max_readers=512,\n",
    "            lock=False,\n",
    "            map_size=int(1e9),\n",
    "        )\n",
    "\n",
    "        # get keys\n",
    "        with self._env.begin(write=False, buffers=True) as txn:\n",
    "            bkeys = txn.get(\"__keys__\".encode())\n",
    "            if bkeys is None:\n",
    "                bkeys = txn.get(\"keys\".encode())\n",
    "                if bkeys is None:\n",
    "                    raise RuntimeError(\"Please preload keys in the LMDB\")\n",
    "            self._keys = set(k.decode() for k in pickle.loads(bkeys))\n",
    "\n",
    "        self.key_split = \"_\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self._path.stem}.{int(self._path.lstat().st_ctime)}'\n",
    "\n",
    "    @property\n",
    "    def keys(self):\n",
    "        return self._keys\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "\n",
    "    def __getitem__(self, keys: List[str]) -> List:\n",
    "        items = [None] * len(keys)\n",
    "\n",
    "        for i, key in enumerate(keys):\n",
    "            if not isinstance(key, str) or key not in self.keys:\n",
    "                raise TypeError(f\"invalid key: {key}\")\n",
    "\n",
    "        with self._env.begin(write=False) as txn:\n",
    "            for i, key in enumerate(keys):\n",
    "                if items[i] is not None:\n",
    "                    continue\n",
    "                item = txn.get(key.encode())\n",
    "                if item is None:\n",
    "                    continue\n",
    "                items[i] = pickle.loads(item)\n",
    "\n",
    "        return items\n",
    "    \n",
    "    \n",
    "pre_extracted_lmdb = '/scratch/jeanzay/work/src/eqlv2/matterport-eqlv2.lmdb'\n",
    "reader = FeaturesReader(pre_extracted_lmdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = next(iter(reader.keys))\n",
    "# 17DRP5sb8fy 08c774f20c984008882da2b8547850eb\n",
    "features = reader[[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load corresponding images\n",
    "feats = dataset.txn.get(key.encode('ascii'))\n",
    "feats = pickle.loads(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key, feature.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft['boxes'].long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for view_id in range(36):\n",
    "    mask = ft['view_ids'] == view_id\n",
    "    if not mask.any():\n",
    "        continue\n",
    "    plt.imshow(np.array(feats['image_feat'][view_id])[:, :, ::-1])\n",
    "    ax = plt.gca()\n",
    "\n",
    "    for obj, label, color in zip(ft['boxes'][mask], ft['cls_probs'][mask], mcolors.TABLEAU_COLORS):\n",
    "        h = obj[3] - obj[1]\n",
    "        w = obj[2] - obj[0]\n",
    "        pos = (obj[0], obj[1])\n",
    "        rect = patches.Rectangle(\n",
    "            (pos), w, h, linewidth=1, \n",
    "            label=classes[label.argmax()],\n",
    "            edgecolor=color, \n",
    "            facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    plt.axis('off')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing with filtered BUTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata = {}\n",
    "with h5py.File(os.path.join(data_dir, 'features', 'filtered_butd_bboxes.hdf5'), 'r') as f:\n",
    "    for key in f:\n",
    "        fts = f[key][...]\n",
    "        item = {\n",
    "            'fts': fts\n",
    "        }\n",
    "        for k, v in f[key].attrs.items():\n",
    "            item[k] = v\n",
    "        fdata[key] = item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up classes from LVIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata = {}\n",
    "with h5py.File(os.path.join(data_dir, 'features', 'filtered_butd_bboxes.hdf5'), 'r') as f:\n",
    "    for key in f:\n",
    "        fts = f[key][...]\n",
    "        item = {\n",
    "            'fts': fts\n",
    "        }\n",
    "        for k, v in f[key].attrs.items():\n",
    "            item[k] = v\n",
    "        fdata[key] = item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict eqlv2 features from REVERIE bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats, scan, viewpoint = dataset[2]\n",
    "scan = '17DRP5sb8fy'\n",
    "viewpoint = '08c774f20c984008882da2b8547850eb'\n",
    "view_id = 1\n",
    "key = f'{scan}_{viewpoint}'\n",
    "feats = dataset.txn.get(key.encode('ascii'))\n",
    "feats = pickle.loads(feats)\n",
    "import json\n",
    "from collections import defaultdict\n",
    "with open(f\"data/bbox/{scan}_{viewpoint}.json\") as fid:\n",
    "    data = json.load(fid)[viewpoint]    \n",
    "\n",
    "bbox_per_view_id = defaultdict(list)\n",
    "for obj, details in data.items():\n",
    "    for view_id, box in zip(details['visible_pos'], details['bbox2d']):\n",
    "        bbox_per_view_id[view_id].append(box)\n",
    "\n",
    "im = feats['image_feat'][view_id]\n",
    "bbox = torch.Tensor(bbox_per_view_id[view_id]).cuda()\n",
    "bbox[:, 2] += bbox[:, 0]\n",
    "bbox[:, 3] += bbox[:, 1]\n",
    "\n",
    "results = inference_detector(model, np.array(im), [bbox])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[classes[l] for l in results['labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['bbox'].long()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
